{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044217fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
    "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
    "import kagglehub\n",
    "kagglehub.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store_sales_time_series_forecasting_path = kagglehub.competition_download('store-sales-time-series-forecasting')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47603b98",
   "metadata": {},
   "source": [
    "# Sales Prediction with LightGBM ( store sales)\n",
    "\n",
    "Enhanced version:\n",
    "- More lag/rolling features (short and long-term)\n",
    "- Exponentially weighted moving averages\n",
    "- Holiday & promotion interaction features\n",
    "- Proper categorical encoding\n",
    "\n",
    "## Exploratory Time Series Analysis\n",
    "\n",
    "To understand trends and autocorrelation, let's visualize an example store-family combination's sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1be708",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet lightgbm statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from datetime import timedelta\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825a79d",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the train, test, stores, oil prices, and holidays datasets.  \n",
    "Parse the date columns for proper time series handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/kaggle/input/store-sales-time-series-forecasting\"\n",
    "train = pd.read_csv(os.path.join(INPUT_DIR, \"train.csv\"), parse_dates=[\"date\"])\n",
    "test = pd.read_csv(os.path.join(INPUT_DIR, \"test.csv\"), parse_dates=[\"date\"])\n",
    "stores = pd.read_csv(os.path.join(INPUT_DIR, \"stores.csv\"))\n",
    "oil = pd.read_csv(os.path.join(INPUT_DIR, \"oil.csv\"), parse_dates=[\"date\"])\n",
    "holidays = pd.read_csv(os.path.join(INPUT_DIR, \"holidays_events.csv\"), parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4d422",
   "metadata": {},
   "source": [
    "## Quick Preprocessing\n",
    "\n",
    "- Create a unique identifier for store-family combinations  \n",
    "- Forward-fill oil prices  \n",
    "- Filter holidays to national only and create a flag  \n",
    "- Merge exogenous features (oil, holidays) into train/test  \n",
    "- Encode store metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c383fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"unique_id\"] = train[\"store_nbr\"].astype(str) + \"_\" + train[\"family\"]\n",
    "test[\"unique_id\"] = test[\"store_nbr\"].astype(str) + \"_\" + test[\"family\"]\n",
    "\n",
    "# Oil: forward fill\n",
    "oil = oil.set_index(\"date\").asfreq(\"D\").ffill().reset_index().rename(columns={\"dcoilwtico\":\"oil_price\"})\n",
    "\n",
    "# Holidays: national only\n",
    "holidays = holidays[holidays[\"locale\"]==\"National\"].copy()\n",
    "holidays[\"holiday_flag\"] = 1\n",
    "holidays = holidays[[\"date\",\"holiday_flag\"]].drop_duplicates()\n",
    "\n",
    "def merge_exog(df):\n",
    "    df = df.merge(oil, on=\"date\", how=\"left\")\n",
    "    df = df.merge(holidays, on=\"date\", how=\"left\")\n",
    "    df[\"holiday_flag\"] = df[\"holiday_flag\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "train = merge_exog(train)\n",
    "test = merge_exog(test)\n",
    "\n",
    "# Encode store metadata\n",
    "stores = stores.rename(columns={\"cluster\":\"store_cluster\"})\n",
    "stores[\"store_nbr\"] = stores[\"store_nbr\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d693840",
   "metadata": {},
   "source": [
    "## Exploratory Analysis Plots\n",
    "\n",
    "- Plot the full sales series for a representative store-family combination  \n",
    "- Zoom in on the first 36 days to see short-term trends  \n",
    "- Plot autocorrelation to examine temporal dependencies  \n",
    "- Perform Augmented Dickey-Fuller test to check stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be831b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example store-family combination\n",
    "example_uid = train.groupby(\"unique_id\")[\"sales\"].sum().idxmax()\n",
    "ts = train[train[\"unique_id\"]==example_uid].sort_values(\"date\")\n",
    "\n",
    "# Full series plot\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(ts[\"date\"], ts[\"sales\"], color=\"blue\", linestyle=\"-\")\n",
    "plt.title(f\"Sales over time for {example_uid}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zoom-in plot (first 36 points)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(ts[\"date\"][:36], ts[\"sales\"][:36], color=\"blue\", linestyle=\"-\")\n",
    "plt.title(f\"Zoom-in on first 36 days for {example_uid}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(ts[\"sales\"], lags=50)\n",
    "plt.title(f\"Autocorrelation of Sales for {example_uid}\")\n",
    "plt.show()\n",
    "\n",
    "# Augmented Dickey-Fuller test\n",
    "adf_result = adfuller(ts[\"sales\"])\n",
    "print(f\"ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"p-value: {adf_result[1]:.4f}\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"Critical Value ({key}): {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da11c10",
   "metadata": {},
   "source": [
    "## Prepare Panel Data\n",
    "\n",
    "- Concatenate train and test to create a full panel  \n",
    "- Sort by unique_id and date  \n",
    "- Merge store metadata  \n",
    "- Generate basic date features (day of week, month, year, week of year)  \n",
    "- Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"sales\"] = np.nan\n",
    "df_all = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "df_all = df_all.sort_values([\"unique_id\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "# Merge store metadata\n",
    "df_all = df_all.merge(stores, on=\"store_nbr\", how=\"left\")\n",
    "\n",
    "# Basic date features\n",
    "df_all[\"dow\"] = df_all[\"date\"].dt.dayofweek\n",
    "df_all[\"day\"] = df_all[\"date\"].dt.day\n",
    "df_all[\"month\"] = df_all[\"date\"].dt.month\n",
    "df_all[\"year\"] = df_all[\"date\"].dt.year\n",
    "df_all[\"weekofyear\"] = df_all[\"date\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Label encode categorical columns\n",
    "for c in [\"family\",\"city\",\"state\",\"type\",\"store_cluster\"]:\n",
    "    df_all[c] = df_all[c].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    df_all[c] = le.fit_transform(df_all[c].fillna(\"NA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0504d1e",
   "metadata": {},
   "source": [
    "## Create Lags, Rolling Windows, EWMA\n",
    "\n",
    "- Generate lag features for short and long-term dependencies  \n",
    "- Compute rolling mean and std for multiple windows  \n",
    "- Compute exponentially weighted moving averages  \n",
    "- Create lagged promotion features and holiday interactions  \n",
    "- Fill missing values with median per series or zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAGS = [1,2,3,7,14,21,28,56]\n",
    "ROLL_WINDOWS = [3,7,14,28,56]\n",
    "\n",
    "for lag in LAGS:\n",
    "    df_all[f\"lag_{lag}\"] = df_all.groupby(\"unique_id\")[\"sales\"].shift(lag)\n",
    "\n",
    "for w in ROLL_WINDOWS:\n",
    "    df_all[f\"rmean_{w}\"] = df_all.groupby(\"unique_id\")[\"sales\"].shift(1).rolling(window=w, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df_all[f\"rstd_{w}\"] = df_all.groupby(\"unique_id\")[\"sales\"].shift(1).rolling(window=w, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "    df_all[f\"ewm_{w}\"] = df_all.groupby(\"unique_id\")[\"sales\"].shift(1).transform(lambda x: x.ewm(span=w, adjust=False).mean())\n",
    "\n",
    "df_all[\"promo_lag_1\"] = df_all.groupby(\"unique_id\")[\"onpromotion\"].shift(1)\n",
    "df_all[\"promo_roll_7\"] = df_all.groupby(\"unique_id\")[\"onpromotion\"].shift(1).rolling(window=7, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df_all[\"days_to_holiday\"] = df_all.groupby(\"unique_id\")[\"holiday_flag\"].shift(1).fillna(0)\n",
    "df_all[\"days_to_holiday_7\"] = df_all.groupby(\"unique_id\")[\"holiday_flag\"].shift(1).rolling(7, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "group_median = df_all.groupby(\"unique_id\")[\"sales\"].transform(\"median\")\n",
    "lag_cols = [c for c in df_all.columns if \"lag_\" in c or \"rmean_\" in c or \"rstd_\" in c or \"ewm_\" in c or \"promo_\" in c or \"days_to_holiday\" in c]\n",
    "for col in lag_cols:\n",
    "    df_all[col] = df_all[col].fillna(group_median).fillna(0.0)\n",
    "\n",
    "df_all[\"oil_price\"] = df_all[\"oil_price\"].fillna(df_all[\"oil_price\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95bed9",
   "metadata": {},
   "source": [
    "## Train/Validation Split\n",
    "\n",
    "- Use last `h` days as validation, rest as training  \n",
    "- Identify categorical features for LightGBM  \n",
    "- Create LightGBM datasets with categorical handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = test[\"date\"].nunique()\n",
    "train_feat = df_all[df_all[\"sales\"].notna()].copy()\n",
    "test_feat = df_all[df_all[\"sales\"].isna()].copy()\n",
    "\n",
    "features = [f for f in df_all.columns if f not in [\"id\",\"date\",\"sales\",\"unique_id\",\"store_nbr\"]]\n",
    "\n",
    "X_train = train_feat[train_feat[\"date\"] < train_feat[\"date\"].max() - pd.Timedelta(days=h-1)][features]\n",
    "y_train = train_feat[train_feat[\"date\"] < train_feat[\"date\"].max() - pd.Timedelta(days=h-1)][\"sales\"]\n",
    "\n",
    "X_val = train_feat[train_feat[\"date\"] >= train_feat[\"date\"].max() - pd.Timedelta(days=h-1)][features]\n",
    "y_val = train_feat[train_feat[\"date\"] >= train_feat[\"date\"].max() - pd.Timedelta(days=h-1)][\"sales\"]\n",
    "\n",
    "cat_features = [c for c in [\"family\",\"city\",\"state\",\"type\",\"store_cluster\",\"dow\",\"month\",\"year\",\"weekofyear\"] if c in features]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features, free_raw_data=False)\n",
    "lgb_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_features, reference=lgb_train, free_raw_data=False)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"rmse\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.036,\n",
    "    \"num_leaves\": 196,\n",
    "    \"min_data_in_leaf\": 494,\n",
    "    \"feature_fraction\": 0.605,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"bagging_fraction\": 0.606,\n",
    "    \"seed\": 2025,\n",
    "    \"verbosity\": -1,\n",
    "    \"n_jobs\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abf63f",
   "metadata": {},
   "source": [
    "## Train LightGBM\n",
    "\n",
    "Train a LightGBM model with early stopping on validation set.  \n",
    "Logs RMSE every 50 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a822d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    valid_names=[\"train\",\"valid\"],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f4feb",
   "metadata": {},
   "source": [
    "## Validation RMSLE\n",
    "\n",
    "Evaluate model predictions on the validation set using RMSLE (Root Mean Squared Log Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dbc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "val_pred = np.clip(val_pred, 0, None)\n",
    "rmsle = np.sqrt(np.mean((np.log1p(val_pred) - np.log1p(y_val))**2))\n",
    "print(f\"Validation RMSLE: {rmsle:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9f7ca",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Visualize the top 20 features according to gain from the LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({\"feature\": model.feature_name(), \"gain\": model.feature_importance(\"gain\")})\n",
    "imp = imp.sort_values(\"gain\", ascending=False).reset_index(drop=True)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(imp[\"feature\"].head(20)[::-1], imp[\"gain\"].head(20)[::-1])\n",
    "plt.title(\"Top 20 feature importances (gain)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8b6ba",
   "metadata": {},
   "source": [
    "## Predict on Test Set and Save Submission\n",
    "\n",
    "- Predict sales on the test set using the trained model  \n",
    "- Fill missing predictions with the median sales per series  \n",
    "- Clip predictions to avoid negative values  \n",
    "- Save submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1602d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_feat[features].copy()\n",
    "preds_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "preds_test = np.clip(preds_test, 0, None)\n",
    "\n",
    "test_feat[\"pred_sales\"] = preds_test\n",
    "\n",
    "# merge back to original test\n",
    "test_out = test.merge(test_feat[[\"unique_id\",\"date\",\"pred_sales\"]], on=[\"unique_id\",\"date\"], how=\"left\")\n",
    "median_sales = train.groupby(\"unique_id\")[\"sales\"].median().to_dict()\n",
    "test_out[\"sales\"] = test_out.apply(lambda r: median_sales.get(r[\"unique_id\"], 0.0) if pd.isna(r[\"pred_sales\"]) else r[\"pred_sales\"], axis=1)\n",
    "test_out[\"sales\"] = test_out[\"sales\"].clip(lower=0.0)\n",
    "\n",
    "submission = test_out[[\"id\",\"sales\"]].copy()\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv with\", submission.shape[0], \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fda61",
   "metadata": {},
   "source": [
    "## Plot Example Forecast\n",
    "\n",
    "- Plot historical sales and predicted sales for the same example store-family combination  \n",
    "- Visual comparison helps to assess forecast quality visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_uid = train.groupby(\"unique_id\")[\"sales\"].sum().idxmax()\n",
    "hist = train[train[\"unique_id\"]==example_uid].sort_values(\"date\")\n",
    "preds_example = test_out[test_out[\"unique_id\"]==example_uid].sort_values(\"date\")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(hist[\"date\"], hist[\"sales\"], label=\"History\", color=\"tab:blue\")\n",
    "plt.plot(preds_example[\"date\"], preds_example[\"sales\"], label=\"Predicted (test)\", color=\"tab:orange\")\n",
    "plt.title(f\"History & predictions for {example_uid}\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Sales\")\n",
    "plt.legend(); plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
